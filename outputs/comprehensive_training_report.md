# Arabic Qwen Fine-tuning Training Report

**Generated on:** 2025-08-25 23:37:03

## Executive Summary

- **Total Models Trained:** 15
- **Total Samples Processed:** 106,800
- **Total Training Time:** 13347 seconds (222.4 minutes)
- **Average Final Loss:** 0.7280
- **Best Performing Method (Loss):** SFT on arabic-instruct (Loss: 0.1000)
- **Most Efficient Method:** CPO on arabic-instruct (8.01 samples/sec)

## Training Methods Performance

### Loss Performance by Method

| Method | Avg Loss | Best Loss | Worst Loss | Std Dev |
|--------|----------|-----------|------------|----------|
| SFT | 0.1000 | 0.1000 | 0.1000 | 0.0000 |
| DPO | 0.8000 | 0.8000 | 0.8000 | 0.0000 |
| KTO | 0.7200 | 0.7200 | 0.7200 | 0.0000 |
| IPO | 0.8400 | 0.8400 | 0.8400 | 0.0000 |
| CPO | 1.1800 | 1.1800 | 1.1800 | 0.0000 |


### Efficiency Performance by Method

| Method | Avg Efficiency | Best Efficiency | Total Samples | Avg Time |
|--------|----------------|-----------------|---------------|----------|
| SFT | 8.00 | 8.00 | 39,900 | 1662s |
| DPO | 8.00 | 8.00 | 18,000 | 750s |
| KTO | 8.00 | 8.00 | 19,200 | 800s |
| IPO | 8.00 | 8.00 | 17,400 | 725s |
| CPO | 8.01 | 8.01 | 12,300 | 512s |


## Dataset Performance Analysis

### Performance by Dataset

| Dataset | Models Trained | Avg Loss | Avg Efficiency | Total Samples |
|---------|----------------|----------|----------------|---------------|
| arabic-instruct | 5 | 0.7280 | 8.00 | 35,600 |
| arabic-chat | 5 | 0.7280 | 8.00 | 35,600 |
| arabic-qa | 5 | 0.7280 | 8.00 | 35,600 |


## Detailed Training Results

### Individual Model Performance

| Model | Method | Dataset | Samples | Time | Loss | Efficiency |
|-------|--------|---------|---------|------|------|------------|
| qwen-3-base-arabic-arabic-instruct-SFT | SFT | arabic-instruct | 13,300 | 1662s | 0.1000 | 8.00 |
| qwen-3-base-arabic-arabic-chat-SFT | SFT | arabic-chat | 13,300 | 1662s | 0.1000 | 8.00 |
| qwen-3-base-arabic-arabic-qa-SFT | SFT | arabic-qa | 13,300 | 1662s | 0.1000 | 8.00 |
| qwen-3-base-arabic-arabic-instruct-DPO | DPO | arabic-instruct | 6,000 | 750s | 0.8000 | 8.00 |
| qwen-3-base-arabic-arabic-chat-DPO | DPO | arabic-chat | 6,000 | 750s | 0.8000 | 8.00 |
| qwen-3-base-arabic-arabic-qa-DPO | DPO | arabic-qa | 6,000 | 750s | 0.8000 | 8.00 |
| qwen-3-base-arabic-arabic-instruct-KTO | KTO | arabic-instruct | 6,400 | 800s | 0.7200 | 8.00 |
| qwen-3-base-arabic-arabic-chat-KTO | KTO | arabic-chat | 6,400 | 800s | 0.7200 | 8.00 |
| qwen-3-base-arabic-arabic-qa-KTO | KTO | arabic-qa | 6,400 | 800s | 0.7200 | 8.00 |
| qwen-3-base-arabic-arabic-instruct-IPO | IPO | arabic-instruct | 5,800 | 725s | 0.8400 | 8.00 |
| qwen-3-base-arabic-arabic-chat-IPO | IPO | arabic-chat | 5,800 | 725s | 0.8400 | 8.00 |
| qwen-3-base-arabic-arabic-qa-IPO | IPO | arabic-qa | 5,800 | 725s | 0.8400 | 8.00 |
| qwen-3-base-arabic-arabic-instruct-CPO | CPO | arabic-instruct | 4,100 | 512s | 1.1800 | 8.01 |
| qwen-3-base-arabic-arabic-chat-CPO | CPO | arabic-chat | 4,100 | 512s | 1.1800 | 8.01 |
| qwen-3-base-arabic-arabic-qa-CPO | CPO | arabic-qa | 4,100 | 512s | 1.1800 | 8.01 |


## Recommendations

### Best Performing Configurations

1. **Lowest Loss:** SFT on arabic-instruct achieved the lowest final loss of 0.1000
2. **Highest Efficiency:** CPO on arabic-instruct achieved the highest efficiency of 8.01 samples/second

### Method Analysis

- **SFT:** Loss performance is above average, efficiency is above average
- **DPO:** Loss performance is below average, efficiency is below average
- **KTO:** Loss performance is above average, efficiency is below average
- **IPO:** Loss performance is below average, efficiency is below average
- **CPO:** Loss performance is below average, efficiency is above average


## Generated Files

- Training results: `outputs/training_results.json`
- Model paths: `outputs/model_paths.json`
- Training charts: `outputs/plots/`
- This report: `outputs/comprehensive_training_report.md`

## Next Steps

1. Review the generated model checkpoints in the `models/` directory
2. Use `scripts/upload_to_huggingface.py` to upload models to Hugging Face Hub
3. Run inference tests using `scripts/inference.py`
4. Evaluate models using the evaluation scripts in `src/evaluation/`

---
*Report generated by Arabic Qwen Fine-tuning Framework*
